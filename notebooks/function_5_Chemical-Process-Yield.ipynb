{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "171eb631",
      "metadata": {},
      "source": [
        "# Function 5: 4D Chemical process yield\n",
        "\n",
        "*Analogy: **Typically unimodal; single peak.**. We **maximize** \\(y\\) (e.g. throughput or reward vs baseline).*\n",
        "\n",
        "### Characteristics\n",
        "\n",
        "* **4D input**: \\((x_1, x_2, x_3, x_4)\\) — e.g. layout or routing parameters in \\([0,1]^4\\).\n",
        "\n",
        "* **Objective**: Maximize \\(y\\). Initial data: initial points, shape (n, 4).\n",
        "\n",
        "* **Strategy**: Same Bayesian optimisation workflow — GP surrogate, EI/PI/UCB acquisition — in 4D; visualisation uses 2D pairwise plots (no single 3D scatter).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e79436eb",
      "metadata": {},
      "source": [
        "## 1. Setup and load data (read-only from initial_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480bbc82",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:38.863748Z",
          "iopub.status.busy": "2026-01-31T21:19:38.863637Z",
          "iopub.status.idle": "2026-01-31T21:19:40.532463Z",
          "shell.execute_reply": "2026-01-31T21:19:40.531764Z"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern, WhiteKernel\n",
        "from scipy.stats import norm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Project root: works whether you run from repo root or from notebooks/\n",
        "repo_root = Path.cwd() if (Path.cwd() / \"src\").exists() else Path.cwd().parent\n",
        "sys.path.insert(0, str(repo_root))\n",
        "\n",
        "from src.utils.load_challenge_data import (\n",
        "    load_function_data, \n",
        "    assert_not_under_initial_data\n",
        ")\n",
        "from src.optimizers.bayesian.acquisition_functions import (\n",
        "    entropy_search,\n",
        "    expected_improvement,\n",
        "    probability_of_improvement,\n",
        "    thompson_sampling_sample,\n",
        "    upper_confidence_bound,\n",
        ")\n",
        "from src.utils.plot_utilities import (\n",
        "    add_colorbar,\n",
        "    style_axis,\n",
        "    style_axis_3d,\n",
        "    style_legend,\n",
        "    DEFAULT_FONT_SIZE_AXIS,\n",
        "    DEFAULT_FONT_SIZE_TITLES,\n",
        "    DEFAULT_EXPORT_DPI,\n",
        "    DEFAULT_EXPORT_FORMAT,\n",
        ")\n",
        "\n",
        "# --- Plot options; font/export defaults from utils (DEFAULT_*) ---\n",
        "IF_SHOW_PLOT = True\n",
        "IF_EXPORT_PLOT = True\n",
        "PLOT_EXPORT_DIR = repo_root / \"data\" / \"results\"\n",
        "\n",
        "IF_EXPORT_QUERIES = True\n",
        "IF_APPEND_DATA = False\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621a23bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:40.534989Z",
          "iopub.status.busy": "2026-01-31T21:19:40.534720Z",
          "iopub.status.idle": "2026-01-31T21:19:40.542198Z",
          "shell.execute_reply": "2026-01-31T21:19:40.541485Z"
        }
      },
      "outputs": [],
      "source": [
        "# Load: prefer local appended data (inputs.npy/outputs.npy), else initial local copy, else initial_data (read-only)\n",
        "local_dir = repo_root / \"data\" / \"problems\" / \"function_5\"\n",
        "local_inputs = local_dir / \"inputs.npy\"\n",
        "local_outputs = local_dir / \"outputs.npy\"\n",
        "if local_inputs.exists() and local_outputs.exists():\n",
        "    X = np.load(local_inputs)\n",
        "    y = np.load(local_outputs)\n",
        "    if y.ndim > 1:\n",
        "        y = y.squeeze()\n",
        "    print(\"Loaded from local data (initial + appended):\", local_dir)\n",
        "else:\n",
        "    local_inputs = local_dir / \"initial_inputs.npy\"\n",
        "    local_outputs = local_dir / \"initial_outputs.npy\"\n",
        "    if local_inputs.exists() and local_outputs.exists():\n",
        "        X = np.load(local_inputs)\n",
        "        y = np.load(local_outputs)\n",
        "        if y.ndim > 1:\n",
        "            y = y.squeeze()\n",
        "        print(\"Loaded from local data (initial):\", local_dir)\n",
        "    else:\n",
        "        X, y = load_function_data(function_id=5)\n",
        "        print(\"Loaded from initial_data (read-only). Run 'Append data' after portal feedback to build local dataset.\")\n",
        "\n",
        "print('Dataset info:')\n",
        "print('Location of the dataset: ', local_dir)\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "print(f\"X max value: {X.max():.6f}\")\n",
        "print(f\"X min value: {X.min():.6f}\")\n",
        "print(f\"y max value: {y.max():.6f}\")\n",
        "print(f\"y min value: {y.min():.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef30a86e",
      "metadata": {},
      "source": [
        "## 2. Visualize the initial points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb4f3f3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:40.544102Z",
          "iopub.status.busy": "2026-01-31T21:19:40.543968Z",
          "iopub.status.idle": "2026-01-31T21:19:41.317870Z",
          "shell.execute_reply": "2026-01-31T21:19:41.317089Z"
        }
      },
      "outputs": [],
      "source": [
        "# 4D Chemical process yield: visualise observations (2D pairwise only; no single 3D scatter for 4D)\n",
        "# Candidate set for GP/acquisition (4D): random sample in [0,1]^4\n",
        "n_cand = 2000\n",
        "candidate_pts = np.random.RandomState(42).uniform(0, 1, (n_cand, 4))\n",
        "# Distance from each candidate to nearest observation (for baseline \"high distance\" suggestion)\n",
        "diff = candidate_pts[:, None, :] - X[None, :, :]  # (n_cand, n_obs, 4)\n",
        "dists = np.sqrt((diff ** 2).sum(axis=2))\n",
        "min_dist = np.min(dists, axis=1)  # (n_cand,)\n",
        "\n",
        "# 2D pairwise plots: all 6 pairs (x_1 vs x_2, x_1 vs x_3, x_1 vs x_4, x_2 vs x_3, x_2 vs x_4, x_3 vs x_4)\n",
        "fig2, axes = plt.subplots(2, 3, figsize=(12, 8), constrained_layout=True)\n",
        "axes = axes.ravel()\n",
        "pairs = [(0, 1, \"x_1\", \"x_2\"), (0, 2, \"x_1\", \"x_3\"), (0, 3, \"x_1\", \"x_4\"), (1, 2, \"x_2\", \"x_3\"), (1, 3, \"x_2\", \"x_4\"), (2, 3, \"x_3\", \"x_4\")]\n",
        "for ax, (i, j, li, lj) in zip(axes, pairs):\n",
        "    sc = ax.scatter(X[:, i], X[:, j], c=y, s=50, cmap=\"inferno\", edgecolors=\"k\")\n",
        "    style_axis(ax, xlabel=li, ylabel=lj, title=f\"{li} vs {lj}\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    ax.set_aspect(\"equal\")\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "sm = plt.cm.ScalarMappable(norm=plt.Normalize(y.min(), y.max()), cmap=\"inferno\")\n",
        "sm.set_array(y)\n",
        "cbar = fig2.colorbar(sm, ax=axes, shrink=0.6, label=\"y\")\n",
        "cbar.ax.tick_params(labelsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "\n",
        "if IF_EXPORT_PLOT:\n",
        "    out_dir = PLOT_EXPORT_DIR\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path_2d = out_dir / f\"function_5_observations_2d_pairs.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig2.savefig(out_path_2d, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path_2d)\n",
        "if IF_SHOW_PLOT:\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec560d5",
      "metadata": {},
      "source": [
        "## 3. Suggest next point to submit, using Bayesian Optimization Methodology\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c08206c",
      "metadata": {},
      "source": [
        "### 3.1 The Probabilistic Surrogate Models\n",
        "\n",
        " * **Gaussian Process (GP)** — we compare three kernel choices below; each gives a different prior over functions and uncertainty:\n",
        "\n",
        "    - **RBF kernel** — Smooth, infinitely differentiable prior; single length-scale. *Differs:* no explicit noise term (fixed small `alpha` for stability).\n",
        "\n",
        "    - **Matérn kernel (ν=1.5)** — Less smooth than RBF; allows rougher, more \"wiggly\" surfaces. *Differs:* better when the true function has sharper changes or only finitely many derivatives.\n",
        "\n",
        "    - **RBF + WhiteKernel** — Same smoothness as RBF but adds a separate noise term. *Differs:* explicitly models observation noise; uncertainty splits into noise vs interpolation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82f900b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:41.319927Z",
          "iopub.status.busy": "2026-01-31T21:19:41.319805Z",
          "iopub.status.idle": "2026-01-31T21:19:41.322499Z",
          "shell.execute_reply": "2026-01-31T21:19:41.321928Z"
        }
      },
      "outputs": [],
      "source": [
        "# Coefficients of the Probabilistic Surrogate Models (used by GP kernels and acquisition functions below)\n",
        "\n",
        "# --- GP / kernel (surrogate) ---\n",
        "CONSTANT_KERNEL_SCALE = 1.0       # signal variance (output scale); typical: 0.1–10\n",
        "LENGTH_SCALE = 0.1                # correlation length; typical for [0,1]²: 0.1–1\n",
        "GP_ALPHA = 1e-6                   # diagonal jitter for numerical stability; typical: 1e-8–1e-4\n",
        "MATERN_NU = 1.5                   # Matérn smoothness (1.5 = once differentiable); typical: 0.5, 1.5, 2.5\n",
        "WHITE_NOISE_LEVEL = 1e-6         # WhiteKernel observation noise; typical: 1e-8–1e-2\n",
        "\n",
        "# --- Acquisition functions ---   # Prioritise exploration (within typical ranges)\n",
        "XI_EI_PI = 0.18                  # typical [0.01–0.2]; 0.18 = high end\n",
        "KAPPA_UCB = 6.0                  # UCB: μ + κσ; typical 2–6, 6 = strong exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef4c19d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:41.324118Z",
          "iopub.status.busy": "2026-01-31T21:19:41.323958Z",
          "iopub.status.idle": "2026-01-31T21:19:41.336490Z",
          "shell.execute_reply": "2026-01-31T21:19:41.335899Z"
        }
      },
      "outputs": [],
      "source": [
        "# Gaussian Process Regression on 4D (run after visualization cell so candidate_pts exist)\n",
        "# Coefficients from cell above: CONSTANT_KERNEL_SCALE, LENGTH_SCALE, GP_ALPHA\n",
        "kernel_RBF = ConstantKernel(CONSTANT_KERNEL_SCALE) * RBF(length_scale=LENGTH_SCALE)\n",
        "gp_RBF = GaussianProcessRegressor(kernel=kernel_RBF, alpha=GP_ALPHA)\n",
        "gp_RBF.fit(X, y)\n",
        "# Predict on 4D candidate set (1D arrays of length n_cand)\n",
        "mu_gp_RBF, sigma_gp_RBF = gp_RBF.predict(candidate_pts, return_std=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f22737",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:41.338250Z",
          "iopub.status.busy": "2026-01-31T21:19:41.338125Z",
          "iopub.status.idle": "2026-01-31T21:19:42.899756Z",
          "shell.execute_reply": "2026-01-31T21:19:42.899275Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot RBF GP on 2D slices for all 6 4D pairs (mean and std contours)\n",
        "# 4D: fix two dims at median; vary (x_i, x_j) for pairs (0,1), (0,2), (0,3), (1,2), (1,3), (2,3)\n",
        "n_slice = 50\n",
        "ug = np.linspace(0, 1, n_slice)\n",
        "Ug, Vg = np.meshgrid(ug, ug)\n",
        "med = [np.median(X[:, k]) for k in range(4)]\n",
        "\n",
        "pairs = [(0, 1, \"x_1\", \"x_2\"), (0, 2, \"x_1\", \"x_3\"), (0, 3, \"x_1\", \"x_4\"), (1, 2, \"x_2\", \"x_3\"), (1, 3, \"x_2\", \"x_4\"), (2, 3, \"x_3\", \"x_4\")]\n",
        "slices_info = []\n",
        "for ia, ib, la, lb in pairs:\n",
        "    other = [k for k in range(4) if k not in (ia, ib)]\n",
        "    slice_pts = np.zeros((Ug.size, 4))\n",
        "    slice_pts[:, ia] = Ug.ravel()\n",
        "    slice_pts[:, ib] = Vg.ravel()\n",
        "    slice_pts[:, other[0]] = med[other[0]]\n",
        "    slice_pts[:, other[1]] = med[other[1]]\n",
        "    slice_label = f\"x_{other[0]+1},x_{other[1]+1}=med\"\n",
        "    slices_info.append((slice_pts, Ug, Vg, ia, ib, la, lb, slice_label))\n",
        "\n",
        "fig, axes = plt.subplots(6, 2, figsize=(10, 12))\n",
        "for row, (slice_pts, Ag, Bg, ia, ib, la, lb, slice_label) in enumerate(slices_info):\n",
        "    mu_slice, sigma_slice = gp_RBF.predict(slice_pts, return_std=True)\n",
        "    mu_slice = mu_slice.reshape(Ug.shape)\n",
        "    sigma_slice = sigma_slice.reshape(Ug.shape)\n",
        "    ax_mu, ax_sig = axes[row, 0], axes[row, 1]\n",
        "    cf1 = ax_mu.contourf(Ag, Bg, mu_slice, levels=20, cmap=\"viridis\")\n",
        "    add_colorbar(cf1, ax=ax_mu, label=\"μ(x)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, shrink=0.85)\n",
        "    ax_mu.scatter(X[:, ia], X[:, ib], c=\"red\", s=60, edgecolors=\"k\")\n",
        "    style_axis(ax_mu, xlabel=la, ylabel=lb, title=f\"RBF — mean (slice {slice_label})\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    ax_mu.set_aspect(\"equal\")\n",
        "    cf2 = ax_sig.contourf(Ag, Bg, sigma_slice, levels=20, cmap=\"rainbow\")\n",
        "    add_colorbar(cf2, ax=ax_sig, label=\"σ(x)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, shrink=0.85)\n",
        "    ax_sig.scatter(X[:, ia], X[:, ib], c=\"red\", s=60, edgecolors=\"k\")\n",
        "    style_axis(ax_sig, xlabel=la, ylabel=lb, title=f\"RBF — std (slice {slice_label})\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    ax_sig.set_aspect(\"equal\")\n",
        "plt.tight_layout()\n",
        "if IF_EXPORT_PLOT:\n",
        "    out_dir = PLOT_EXPORT_DIR\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path = out_dir / f\"function_5_gp_slices.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig.savefig(out_path, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path)\n",
        "if IF_SHOW_PLOT:\n",
        "    plt.show()  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f87a6352",
      "metadata": {},
      "source": [
        "### 3.2 The Acquisition Functions $\\alpha$(x)\n",
        "\n",
        "* Expected Improvement (EI)\n",
        "\n",
        "* Upper Confidence Bound (UCB)\n",
        "\n",
        "* Probability of Improvement (PI)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c68ac81",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:42.903595Z",
          "iopub.status.busy": "2026-01-31T21:19:42.903452Z",
          "iopub.status.idle": "2026-01-31T21:19:42.907676Z",
          "shell.execute_reply": "2026-01-31T21:19:42.907041Z"
        }
      },
      "outputs": [],
      "source": [
        "# ACQUISITION FUNCTION(s) — on 4D candidate_pts (mu_gp_RBF, sigma_gp_RBF are 1D arrays of length n_cand)\n",
        "\n",
        "# --- EXPECTED IMPROVEMENT: EI = E[max(f(x) − f(x⁺), 0)] ---\n",
        "y_best_EI = y.max()\n",
        "EI_RBF = expected_improvement(mu_gp_RBF, sigma_gp_RBF, y_best_EI, xi=XI_EI_PI)\n",
        "x_best_EI_RBF = candidate_pts[np.argmax(EI_RBF)]\n",
        "\n",
        "# --- UPPER CONFIDENCE BOUND: UCB = μ(x) + κσ(x) ---\n",
        "UCB_RBF = upper_confidence_bound(mu_gp_RBF, sigma_gp_RBF, kappa=KAPPA_UCB)\n",
        "x_best_UCB_RBF = candidate_pts[np.argmax(UCB_RBF)]\n",
        "\n",
        "# --- PROBABILITY OF IMPROVEMENT: PI = P(f(x) > f(x⁺)) ---\n",
        "PI_RBF = probability_of_improvement(mu_gp_RBF, sigma_gp_RBF, y_best_EI, xi=XI_EI_PI)\n",
        "x_best_PI_RBF = candidate_pts[np.argmax(PI_RBF)]\n",
        "\n",
        "# --- THOMPSON SAMPLING ---\n",
        "sample_thompson_RBF = thompson_sampling_sample(mu_gp_RBF, sigma_gp_RBF)\n",
        "x_thomson_RBF = candidate_pts[np.argmax(sample_thompson_RBF)]\n",
        "\n",
        "# --- ENTROPY SEARCH ---\n",
        "ES_RBF = entropy_search(mu_gp_RBF, sigma_gp_RBF, y_best_EI, xi=XI_EI_PI)\n",
        "x_entropy_RBF = candidate_pts[np.argmax(ES_RBF)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7db2f1f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:42.909339Z",
          "iopub.status.busy": "2026-01-31T21:19:42.909211Z",
          "iopub.status.idle": "2026-01-31T21:19:42.912039Z",
          "shell.execute_reply": "2026-01-31T21:19:42.911471Z"
        }
      },
      "outputs": [],
      "source": [
        "# Baseline: suggest next x without GP — point with highest distance to nearest observation (explore far from data).\n",
        "idx_high_dist = np.argmax(min_dist)\n",
        "next_x_high_dist = np.asarray(candidate_pts[idx_high_dist]).ravel()\n",
        "next_x_high_dist = np.clip(next_x_high_dist, 0.0, 0.999999)\n",
        "next_x = next_x_high_dist\n",
        "print(\"Suggested next x (high distance to obs):\", next_x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8f3b3c",
      "metadata": {},
      "source": [
        "## 4. Illustrate the locations on the proposed query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "section4_acquisition_plot",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:42.913513Z",
          "iopub.status.busy": "2026-01-31T21:19:42.913397Z",
          "iopub.status.idle": "2026-01-31T21:19:43.707073Z",
          "shell.execute_reply": "2026-01-31T21:19:43.706553Z"
        }
      },
      "outputs": [],
      "source": [
        "# PLOT EI + PI + UCB (acquisition next points) — 4D: 2D pairwise only (6 pairs, no 3D scatter)\n",
        "\n",
        "X_best_combined = np.array([x_best_EI_RBF, x_best_PI_RBF, x_best_UCB_RBF])\n",
        "labels_combined = ['EI RBF', 'PI RBF', 'UCB RBF']\n",
        "colors_combined = plt.cm.cool(np.linspace(0, 1, len(X_best_combined)))\n",
        "\n",
        "# 2D pairwise view (all 6 pairs) — same layout as observations\n",
        "fig2, axes = plt.subplots(2, 3, figsize=(12, 8), constrained_layout=True)\n",
        "axes = axes.ravel()\n",
        "pairs = [(0, 1, \"x_1\", \"x_2\"), (0, 2, \"x_1\", \"x_3\"), (0, 3, \"x_1\", \"x_4\"), (1, 2, \"x_2\", \"x_3\"), (1, 3, \"x_2\", \"x_4\"), (2, 3, \"x_3\", \"x_4\")]\n",
        "for ax, (i, j, li, lj) in zip(axes, pairs):\n",
        "    sc = ax.scatter(X[:, i], X[:, j], c=y, s=50, cmap=\"inferno\", edgecolors=\"k\", zorder=2)\n",
        "    for k, (pt, lbl) in enumerate(zip(X_best_combined, labels_combined)):\n",
        "        ax.scatter(pt[i], pt[j], c=[colors_combined[k]], s=100, marker='s', edgecolors=\"k\", linewidths=1.5, alpha=0.95, label=lbl, zorder=3)\n",
        "        ax.annotate(lbl, (pt[i], pt[j]), xytext=(5, 5), textcoords=\"offset points\", fontsize=DEFAULT_FONT_SIZE_AXIS, alpha=0.9, zorder=4)\n",
        "    style_axis(ax, xlabel=li, ylabel=lj, title=f\"{li} vs {lj}\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    ax.set_aspect(\"equal\")\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "axes[0].legend(loc=\"upper right\", fontsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "sm = plt.cm.ScalarMappable(norm=plt.Normalize(y.min(), y.max()), cmap=\"inferno\")\n",
        "sm.set_array(y)\n",
        "cbar = fig2.colorbar(sm, ax=axes, shrink=0.6, label=\"y\")\n",
        "cbar.ax.tick_params(labelsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "\n",
        "if IF_SHOW_PLOT:\n",
        "    plt.show()\n",
        "if IF_EXPORT_PLOT:\n",
        "    out_dir = PLOT_EXPORT_DIR\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path_2d = out_dir / f\"function_5_acquisition_points_2d_pairs.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig2.savefig(out_path_2d, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path_2d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e60d91b",
      "metadata": {},
      "source": [
        "## 5. Choose next query\n",
        "\n",
        "Pick the next input to submit. **EI RBF** (Expected Improvement with RBF kernel) is the default. **Strategy:** Start with EI and **max exploration** — in the coefficients cell (Section 3.1), `XI_EI_PI = 0.1` gives strong exploration (higher than the usual 0.01); you can try 0.2 for even more. See how it goes; later you can lower it for more exploitation. Alternative: `next_x_high_dist` (high distance to obs — explore unexplored regions).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fdb4f7a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:43.709094Z",
          "iopub.status.busy": "2026-01-31T21:19:43.708952Z",
          "iopub.status.idle": "2026-01-31T21:19:43.711699Z",
          "shell.execute_reply": "2026-01-31T21:19:43.711184Z"
        }
      },
      "outputs": [],
      "source": [
        "# In this cell we select the next query to submit (4D: x_1, x_2, x_3, x_4).\n",
        "# Prioritise exploration — UCB (or next_x_high_dist to explore far from data).\n",
        "next_x = x_best_UCB_RBF  # UCB favours uncertain regions; or next_x_high_dist, x_best_EI_RBF\n",
        "next_x = np.clip(np.asarray(next_x).ravel(), 0.0, 0.999999)\n",
        "print(\"Next query (EI RBF):\", \", \".join(f\"{next_x[i]:.4f}\" for i in range(4)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebbef23",
      "metadata": {},
      "source": [
        "## 6. Append new feedback (after portal returns)\n",
        "\n",
        "After you submit and receive the new **(x, y)** from the portal for Function 4, paste the values below and run this cell. It appends to a local dataset under `data/problems/function_4/`. The next time you run the notebook from the top, section 1 will load from this local dataset (initial + all appended points).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02545945",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:43.713113Z",
          "iopub.status.busy": "2026-01-31T21:19:43.712979Z",
          "iopub.status.idle": "2026-01-31T21:19:43.716703Z",
          "shell.execute_reply": "2026-01-31T21:19:43.716201Z"
        }
      },
      "outputs": [],
      "source": [
        "if not IF_APPEND_DATA:\n",
        "    print(\"IF_APPEND_DATA is False; append skipped. Set IF_APPEND_DATA = True and paste portal feedback below to run.\")\n",
        "else:\n",
        "    # Paths (use repo_root from setup cell)\n",
        "    _local_dir = repo_root / \"data\" / \"problems\" / \"function_5\"\n",
        "    assert_not_under_initial_data(_local_dir, project_root=repo_root)\n",
        "    _local_inputs = _local_dir / \"inputs.npy\"\n",
        "    _local_outputs = _local_dir / \"outputs.npy\"\n",
        "\n",
        "    # Set these from the portal feedback for Function 5 (one new input (x_1..x_4) and one new output)\n",
        "    x_new = np.array([0.5] * 4, dtype=np.float64)  # replace with your submitted input (4D)\n",
        "    y_new = 0.0  # replace with the output returned by portal (scalar)\n",
        "\n",
        "    # Load current data (local if exists, else initial_data)\n",
        "    if _local_inputs.exists() and _local_outputs.exists():\n",
        "        X_cur = np.load(_local_inputs)\n",
        "        y_cur = np.load(_local_outputs)\n",
        "        if y_cur.ndim > 1:\n",
        "            y_cur = y_cur.squeeze()\n",
        "    else:\n",
        "        X_cur, y_cur = load_function_data(function_id=5)\n",
        "\n",
        "    # Append: one new row for inputs, one new value for outputs\n",
        "    x_new = np.atleast_2d(x_new)\n",
        "    X_updated = np.vstack((X_cur, x_new))\n",
        "    y_updated = np.append(y_cur, y_new)\n",
        "\n",
        "    # Save to local directory (do not overwrite read-only initial_data)\n",
        "    _local_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(_local_dir / \"inputs.npy\", X_updated)\n",
        "    np.save(_local_dir / \"outputs.npy\", y_updated)\n",
        "    print(\"Appended. Total points:\", len(y_updated))\n",
        "    print(\"Saved to\", _local_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a76564",
      "metadata": {},
      "source": [
        "## 7. Save suggestion for submission\n",
        "\n",
        "Write the chosen x to `data/submissions/` so you can upload it to the portal. **Portal format:** `x1-x2-...-xn` with **exactly six decimal places**, values in [0, 0.999999], **hyphens only, no spaces** (e.g. `0.498317-0.625531`). After you receive the new y, run section 6 (Append new feedback) to add it to your dataset, then re-run the notebook for the next round.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f56d52c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:43.718226Z",
          "iopub.status.busy": "2026-01-31T21:19:43.718127Z",
          "iopub.status.idle": "2026-01-31T21:19:43.722612Z",
          "shell.execute_reply": "2026-01-31T21:19:43.722070Z"
        }
      },
      "outputs": [],
      "source": [
        "if IF_EXPORT_QUERIES:\n",
        "    # Portal format: each value 0.XXXXXX (exactly 6 decimals), in [0, 0.999999], hyphen-separated, no spaces\n",
        "    next_x_clip = np.clip(np.asarray(next_x, dtype=np.float64).ravel(), 0.0, 0.999999)\n",
        "    portal_str = \"-\".join(f\"{v:.6f}\" for v in next_x_clip)\n",
        "    out_dir = repo_root / \"data\" / \"submissions\" / \"function_5\"\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(out_dir / \"next_input.npy\", next_x_clip)\n",
        "    (out_dir / \"next_input_portal.txt\").write_text(portal_str)\n",
        "    print(\"Saved to\", out_dir / \"next_input.npy\")\n",
        "    print(\"Portal string (copy-paste to portal):\", portal_str)\n",
        "    print(\"Also saved to\", out_dir / \"next_input_portal.txt\")\n",
        "else:\n",
        "    print(\"IF_EXPORT_QUERIES is False; next_input.npy not saved.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
