{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "445cb823",
      "metadata": {},
      "source": [
        "# Function 1: 2D Radiation Detection\n",
        "\n",
        "Explore the initial 10 (x, y) points, visualize the landscape, and suggest the next input to submit.\n",
        "\n",
        "- 2D, sparse signal (only proximity yields non-zero reading).\n",
        "- One hotspot; goal is to find it with limited queries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d860f2ba",
      "metadata": {},
      "source": [
        "## 1. Setup and load data (read-only from initial_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df893264",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:29.486738Z",
          "iopub.status.busy": "2026-01-31T21:19:29.486496Z",
          "iopub.status.idle": "2026-01-31T21:19:31.262122Z",
          "shell.execute_reply": "2026-01-31T21:19:31.261325Z"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern, WhiteKernel\n",
        "from scipy.stats import norm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Project root: works whether you run from repo root or from notebooks/\n",
        "repo_root = Path.cwd() if (Path.cwd() / \"src\").exists() else Path.cwd().parent\n",
        "sys.path.insert(0, str(repo_root))\n",
        "\n",
        "from src.utils.load_challenge_data import (\n",
        "    load_function_data,\n",
        "    load_problem_data_csv,\n",
        "    save_problem_data_csv,\n",
        "    assert_not_under_initial_data,\n",
        ")\n",
        "from src.optimizers.bayesian.acquisition_functions import (\n",
        "    entropy_search,\n",
        "    expected_improvement,\n",
        "    probability_of_improvement,\n",
        "    thompson_sampling_sample,\n",
        "    upper_confidence_bound,\n",
        ")\n",
        "from src.utils.plot_utilities import (\n",
        "    add_colorbar,\n",
        "    style_axis,\n",
        "    style_axis_3d,\n",
        "    style_legend,\n",
        "    DEFAULT_FONT_SIZE_AXIS,\n",
        "    DEFAULT_FONT_SIZE_TITLES,\n",
        "    DEFAULT_EXPORT_DPI,\n",
        "    DEFAULT_EXPORT_FORMAT,\n",
        ")\n",
        "from src.utils.sampling_utils import sample_candidates\n",
        "\n",
        "# --- Candidate sampling for acquisition maximisation: 'grid', 'lhs', 'sobol', or 'random' ---\n",
        "# grid: regular lattice; best when n ≈ k^dim (e.g. 2D with 80² points). Deterministic.\n",
        "# lhs:  Latin Hypercube; one point per bin per dimension. Good space-filling, reproducible with seed.\n",
        "# sobol: Sobol (quasi-Monte Carlo); low-discrepancy, often better coverage than random. Good default.\n",
        "# random: i.i.d. uniform; simple but can leave gaps. Use for quick tests.\n",
        "# Suitability: sobol/lhs for exploration and even coverage; grid when you want a fixed lattice; random only if others unavailable.\n",
        "CANDIDATE_SAMPLING_METHOD = \"lhs\"\n",
        "\n",
        "# --- Plot options; font/export defaults from utils (DEFAULT) ---\n",
        "IF_SHOW_PLOT = True\n",
        "IF_EXPORT_PLOT = False\n",
        "PLOT_EXPORT_DIR = repo_root / \"data\" / \"results\"\n",
        "\n",
        "IF_EXPORT_QUERIES = False\n",
        "IF_APPEND_DATA = False  # Set True and paste (x1, x2), y in \"Append new feedback\" cell to add new points to the local dataset\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183f0d90",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:31.264170Z",
          "iopub.status.busy": "2026-01-31T21:19:31.263924Z",
          "iopub.status.idle": "2026-01-31T21:19:31.268825Z",
          "shell.execute_reply": "2026-01-31T21:19:31.268320Z"
        }
      },
      "outputs": [],
      "source": [
        "# Load: under data/ we use only CSV. observations.csv if present, else initial_data (read-only).\n",
        "local_dir = repo_root / \"data\" / \"problems\" / \"function_1\"\n",
        "csv_path = local_dir / \"observations.csv\"\n",
        "if csv_path.exists():\n",
        "    X, y = load_problem_data_csv(csv_path)\n",
        "    print(\"Loaded from local CSV (initial + appended):\", csv_path)\n",
        "else:\n",
        "    X, y = load_function_data(function_id=1)\n",
        "    print(\"Loaded from initial_data (read-only). Run append script or 'Append data' after portal feedback.\")\n",
        "print('Dataset info:')\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "print(f\"X max value: {X.max():.6f}\")\n",
        "print(f\"X min value: {X.min():.6f}\")\n",
        "print(f\"y max value: {y.max():.6f}\")\n",
        "print(f\"y min value: {y.min():.6f}\")\n",
        "# Are we getting better? (goal: maximize y)\n",
        "best_idx = np.argmax(y)\n",
        "best_y, best_x_so_far = y[best_idx], X[best_idx]\n",
        "print(f\"\\n>>> Best so far: y = {best_y:.6g} at x = ({best_x_so_far[0]:.4f}, {best_x_so_far[1]:.4f}) | n = {len(y)} points. New portal results improve us if the returned y > {best_y:.6g}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ab08e36",
      "metadata": {},
      "source": [
        "### Progress: are we getting better?\n",
        "Left: **y** at each query (order of observations). Right: **best y so far** (cumulative max) — this line only goes up when a new observation improves on the previous best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a80c9d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Progress line plots: are we getting better over time?\n",
        "import numpy as np\n",
        "n_obs = len(y)\n",
        "obs_idx = np.arange(1, n_obs + 1, dtype=float)\n",
        "best_so_far = np.maximum.accumulate(y)  # running maximum\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "ax1.plot(obs_idx, y, 'o-', color='blue', markersize=5, label='y per observation')\n",
        "ax1.set_xlabel('Observation index')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.set_title('Output y at each query')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "style_axis(ax1, font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "\n",
        "ax2.plot(obs_idx, best_so_far, 'o-', color='red', markersize=5, label='Best y so far')\n",
        "ax2.set_xlabel('Observation index')\n",
        "ax2.set_ylabel('Best y so far')\n",
        "ax2.set_title('Cumulative best (improvement over time)')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "style_axis(ax2, font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3e1296",
      "metadata": {},
      "source": [
        "## 2. Visualize the points\n",
        "\n",
        "**Convention (no mix-up):** `X` has shape (n, 2) with columns **x_1** = `X[:, 0]` and **x_2** = `X[:, 1]`. **y** is the objective value (scalar per row). All 2D plots: horizontal = x_1, vertical = x_2. 3D: floor = (x_1, x_2), height = y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0dd6bbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:31.270267Z",
          "iopub.status.busy": "2026-01-31T21:19:31.270173Z",
          "iopub.status.idle": "2026-01-31T21:19:32.263473Z",
          "shell.execute_reply": "2026-01-31T21:19:32.262860Z"
        }
      },
      "outputs": [],
      "source": [
        "# Grid for contour: distance from each point to nearest observation\n",
        "n_grid = 80\n",
        "x1g = np.linspace(0, 1, n_grid)\n",
        "x2g = np.linspace(0, 1, n_grid)\n",
        "X1g, X2g = np.meshgrid(x1g, x2g)\n",
        "grid_pts = np.column_stack([X1g.ravel(), X2g.ravel()])\n",
        "# Uniform-coverage candidates for acquisition maximisation (grid = lattice; or 'lhs' / 'sobol' / 'random')\n",
        "candidate_pts = sample_candidates(n_grid * n_grid, 2, method=CANDIDATE_SAMPLING_METHOD, seed=42)\n",
        "# Distance from each grid point to nearest of X (L2, numpy only)\n",
        "diff = grid_pts[:, None, :] - X[None, :, :]  # (n_grid^2, n_obs, 2)\n",
        "dists = np.sqrt((diff ** 2).sum(axis=2))\n",
        "min_dist = np.min(dists, axis=1).reshape(X1g.shape)\n",
        "\n",
        "# Interpolate y onto grid (IDW) for 3D surface\n",
        "dist_gx = np.sqrt(((grid_pts[:, None, :] - X[None, :, :]) ** 2).sum(axis=2)) + 1e-12\n",
        "w = 1.0 / (dist_gx ** 2)\n",
        "y_grid = (w * y[None, :]).sum(axis=1) / w.sum(axis=1)\n",
        "Y_grid = y_grid.reshape(X1g.shape)\n",
        "\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "# Left: scatter of observations colored by y\n",
        "sc = ax1.scatter(X[:, 0], X[:, 1], c=y, s=80, cmap=\"inferno\", edgecolors=\"k\")\n",
        "add_colorbar(sc, ax=ax1, label=\"y\", font_size_axis=DEFAULT_FONT_SIZE_AXIS)\n",
        "# Enumerate observations from first to last (1, 2, ..., n)\n",
        "for i in range(len(y)):\n",
        "    ax1.text(X[i, 0] + 0.025, X[i, 1] + 0.025, str(i + 1), fontsize=DEFAULT_FONT_SIZE_AXIS - 1, color=\"black\", ha=\"left\", va=\"bottom\", zorder=10)\n",
        "style_axis(ax1, xlabel=\"x_1\", ylabel=\"x_2\", title=\"Function 2: observations (y)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "ax1.set_aspect(\"equal\")\n",
        "\n",
        "# Right: contour of output y (interpolated)\n",
        "cf = ax2.contourf(X1g, X2g, Y_grid, levels=22, cmap=\"turbo\")\n",
        "add_colorbar(cf, ax=ax2, label=\"y (interpolated)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS)\n",
        "ax2.scatter(X[:, 0], X[:, 1], c=y, s=80, cmap=\"inferno\", edgecolors=\"black\", linewidths=1.5, zorder=2, label=\"points=f(y)\")\n",
        "style_axis(ax2, xlabel=\"x_1\", ylabel=\"x_2\", title=\"y (interpolated)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "ax2.set_aspect(\"equal\")\n",
        "style_legend(ax2, loc=\"upper right\", font_size_axis=DEFAULT_FONT_SIZE_AXIS)\n",
        "\n",
        "# For second figure (3D): norm and mappable for output y colour\n",
        "norm_y = plt.Normalize(Y_grid.min(), Y_grid.max())\n",
        "sm = cm.ScalarMappable(cmap=cm.inferno, norm=norm_y)\n",
        "sm.set_array(Y_grid)\n",
        "\n",
        "if IF_SHOW_PLOT or IF_EXPORT_PLOT:\n",
        "    # Second figure: 3D plot only (standalone; created for display and/or export)\n",
        "    fig2 = plt.figure(figsize=(7, 5))\n",
        "    ax3b = fig2.add_subplot(111, projection=\"3d\")\n",
        "    facecolors = cm.inferno(norm_y(Y_grid))[:-1, :-1]\n",
        "    ax3b.plot_surface(X1g, X2g, Y_grid, facecolors=facecolors, rstride=1, cstride=1, shade=False, alpha=0.8)\n",
        "    ax3b.scatter(X[:, 0], X[:, 1], y, c='black', s=40, edgecolors=\"k\", depthshade=False)\n",
        "    n_pts = len(y)\n",
        "    for i in range(n_pts):\n",
        "        ax3b.text(X[i, 0], X[i, 1], y[i], str(i + 1), fontsize=DEFAULT_FONT_SIZE_AXIS - 2, color=\"white\", ha=\"center\", va=\"center\")\n",
        "    style_axis_3d(ax3b, xlabel=\"x_1\", ylabel=\"x_2\", zlabel=\"y\", title=\"y (*interpolated*), colour = y\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    add_colorbar(sm, ax=ax3b, label=\"y\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, shrink=0.8, pad=0.08)\n",
        "\n",
        "plt.tight_layout()\n",
        "if IF_EXPORT_PLOT:\n",
        "    out_dir = PLOT_EXPORT_DIR\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path_2d = out_dir / f\"function_2_observations_and_distance_contour.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig.savefig(out_path_2d, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path_2d)\n",
        "    out_path_3d = out_dir / f\"function_2_3d_surface_distance_colour.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig2.savefig(out_path_3d, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path_3d)\n",
        "if IF_SHOW_PLOT:\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccbb9820",
      "metadata": {},
      "source": [
        "## 3. Suggest next point to submit, using Bayesian Optimization Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e7d1e7",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3.1 The Probabilistic Surrogate Models\n",
        "\n",
        " * **Gaussian Process (GP)** — we compare three kernel choices below; each gives a different prior over functions and uncertainty:\n",
        "\n",
        "    - **RBF kernel** — Smooth, infinitely differentiable prior; single length-scale. *Differs:* no explicit noise term (fixed small `alpha` for stability).\n",
        "\n",
        "    - **Matérn kernel (ν=1.5)** — Less smooth than RBF; allows rougher, more \"wiggly\" surfaces. *Differs:* better when the true function has sharper changes or only finitely many derivatives.\n",
        "\n",
        "    - **RBF + WhiteKernel** — Same smoothness as RBF but adds a separate noise term. *Differs:* explicitly models observation noise; uncertainty splits into noise vs interpolation.\n",
        "\n",
        " * **Random Forest (RF)** — *Different approach:* non-parametric ensemble of trees; no Gaussian prior or native uncertainty (would need e.g. quantile regression for uncertainty). Not implemented below; listed as an alternative surrogate family.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f53d0f5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.265510Z",
          "iopub.status.busy": "2026-01-31T21:19:32.265380Z",
          "iopub.status.idle": "2026-01-31T21:19:32.267990Z",
          "shell.execute_reply": "2026-01-31T21:19:32.267475Z"
        }
      },
      "outputs": [],
      "source": [
        "# Coefficients of the Probabilistic Surrogate Models (used by GP kernels and acquisition functions below)\n",
        "\n",
        "# --- GP / kernel (surrogate) ---  (F1: sparse hotspot; smaller length scale = more local uncertainty, better for exploration)\n",
        "CONSTANT_KERNEL_SCALE = 1.0       # signal variance (output scale); typical: 0.1–10\n",
        "LENGTH_SCALE = 0.15               # smaller = more local variation, uncertainty in gaps (good when hotspot not found yet)\n",
        "GP_ALPHA = 1e-6                   # diagonal jitter for numerical stability; typical: 1e-8–1e-4\n",
        "MATERN_NU = 1.5                   # Matérn smoothness (1.5 = once differentiable); typical: 0.5, 1.5, 2.5\n",
        "WHITE_NOISE_LEVEL = 1e-6         # WhiteKernel observation noise; typical: 1e-8–1e-2\n",
        "\n",
        "# --- Acquisition functions ---   (F1: favour exploration until we get a non-zero reading)\n",
        "XI_EI_PI = 0.18                   # prioritise exploration; typical range [0.01–0.2], 0.18 = high end\n",
        "KAPPA_UCB = 6.0                   # UCB: μ + κσ; typical 2–6, 6 = strong exploration (within logical limit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52047c63",
      "metadata": {},
      "source": [
        "**Effect of increasing vs decreasing each coefficient**\n",
        "\n",
        "| Coefficient | **Increase** | **Decrease** |\n",
        "|-------------|--------------|--------------|\n",
        "| **CONSTANT_KERNEL_SCALE** | GP prior allows larger swings in the mean μ(x); predictions can vary more in magnitude. | Prior is tighter around zero; mean predictions stay smaller in scale. |\n",
        "| **LENGTH_SCALE** | Smoother surrogate: correlation between points extends farther; fewer “wiggles,” more global structure. | Rougher surrogate: correlation drops off quickly; more local variation, can overfit noise. |\n",
        "| **GP_ALPHA** | More regularization: posterior is smoother, uncertainty (σ) tends to be slightly higher and more stable. | Less regularization: fit tracks data more closely; risk of numerical issues if data are nearly collinear. |\n",
        "| **MATERN_NU** | Smoother Matérn prior (closer to RBF); fewer sharp turns. | Rougher prior; more wiggly surfaces, better for non-smooth functions. |\n",
        "| **WHITE_NOISE_LEVEL** | GP attributes more of the variation to observation noise; posterior uncertainty is higher and less “peaked” near data. | GP attributes more to the latent function; lower σ away from data, higher risk of overconfident extrapolation. |\n",
        "| **XI_EI_PI** (EI, PI, Entropy) | More **exploration**: favours points with higher uncertainty; next query tends to be farther from observed points. | More **exploitation**: favours points near the current best; next query tends to refine the best region. |\n",
        "| **KAPPA_UCB** | UCB = μ + κσ: more weight on σ → more **exploration** (prefer uncertain regions). | Less weight on σ → more **exploitation** (prefer high μ). |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3405afa0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.269450Z",
          "iopub.status.busy": "2026-01-31T21:19:32.269348Z",
          "iopub.status.idle": "2026-01-31T21:19:32.288842Z",
          "shell.execute_reply": "2026-01-31T21:19:32.288359Z"
        }
      },
      "outputs": [],
      "source": [
        "# Gaussian Process Regression (run after visualization cell so X1g, grid_pts exist)\n",
        "# Coefficients from cell above: CONSTANT_KERNEL_SCALE, LENGTH_SCALE, GP_ALPHA, MATERN_NU, WHITE_NOISE_LEVEL\n",
        "kernel_RBF = ConstantKernel(CONSTANT_KERNEL_SCALE) * RBF(length_scale=LENGTH_SCALE)\n",
        "gp_RBF = GaussianProcessRegressor(kernel=kernel_RBF, alpha=GP_ALPHA)\n",
        "gp_RBF.fit(X, y)\n",
        "mu_gp_RBF, sigma_gp_RBF = gp_RBF.predict(grid_pts, return_std=True)\n",
        "mu_gp_RBF = mu_gp_RBF.reshape(X1g.shape)\n",
        "sigma_gp_RBF = sigma_gp_RBF.reshape(X1g.shape)\n",
        "\n",
        "# Matern: same length_scale; MATERN_NU gives rougher prior than RBF\n",
        "kernel_Matern = ConstantKernel(CONSTANT_KERNEL_SCALE) * Matern(length_scale=LENGTH_SCALE, nu=MATERN_NU)\n",
        "gp_Matern = GaussianProcessRegressor(kernel=kernel_Matern, alpha=GP_ALPHA)\n",
        "gp_Matern.fit(X, y)\n",
        "mu_gp_Matern, sigma_gp_Matern = gp_Matern.predict(grid_pts, return_std=True)\n",
        "mu_gp_Matern = mu_gp_Matern.reshape(X1g.shape)\n",
        "sigma_gp_Matern = sigma_gp_Matern.reshape(X1g.shape)\n",
        "\n",
        "# RBF + WhiteKernel: WHITE_NOISE_LEVEL for observation noise\n",
        "kernel_RBF_noise = ConstantKernel(CONSTANT_KERNEL_SCALE) * RBF(length_scale=LENGTH_SCALE) + WhiteKernel(noise_level=WHITE_NOISE_LEVEL)\n",
        "gp_RBF_noise = GaussianProcessRegressor(kernel=kernel_RBF_noise, alpha=GP_ALPHA)\n",
        "gp_RBF_noise.fit(X, y)\n",
        "mu_gp_RBF_noise, sigma_gp_RBF_noise = gp_RBF_noise.predict(grid_pts, return_std=True)\n",
        "mu_gp_RBF_noise = mu_gp_RBF_noise.reshape(X1g.shape)\n",
        "sigma_gp_RBF_noise = sigma_gp_RBF_noise.reshape(X1g.shape)\n",
        "\n",
        "# Predict at candidate_pts for acquisition maximisation (uniform-coverage method from sampling_utils)\n",
        "mu_cand_RBF, sigma_cand_RBF = gp_RBF.predict(candidate_pts, return_std=True)\n",
        "mu_cand_Matern, sigma_cand_Matern = gp_Matern.predict(candidate_pts, return_std=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ded9b009",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.290635Z",
          "iopub.status.busy": "2026-01-31T21:19:32.290498Z",
          "iopub.status.idle": "2026-01-31T21:19:32.829247Z",
          "shell.execute_reply": "2026-01-31T21:19:32.828686Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot all three GPs: mean (left) and std (right) per kernel\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10, 12))\n",
        "kernels_info = [\n",
        "    (mu_gp_RBF, sigma_gp_RBF, \"RBF\"),\n",
        "    (mu_gp_Matern, sigma_gp_Matern, \"Matérn (ν=1.5)\"),\n",
        "    (mu_gp_RBF_noise, sigma_gp_RBF_noise, \"RBF + WhiteKernel\"),\n",
        "]\n",
        "for i, (mu, sig, name) in enumerate(kernels_info):\n",
        "    ax_mu, ax_sig = axes[i, 0], axes[i, 1]\n",
        "    cf1 = ax_mu.contourf(X1g, X2g, mu, levels=20, cmap=\"viridis\")\n",
        "    add_colorbar(cf1, ax=ax_mu, label=\"μ(x)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS)\n",
        "    ax_mu.scatter(X[:, 0], X[:, 1], c=\"red\", s=60, edgecolors=\"k\")\n",
        "    style_axis(ax_mu, xlabel=\"x_1\", ylabel=\"x_2\", title=f\"{name} — mean\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    ax_mu.set_aspect(\"equal\")\n",
        "    cf2 = ax_sig.contourf(X1g, X2g, sig, levels=20, cmap=\"rainbow\")\n",
        "    add_colorbar(cf2, ax=ax_sig, label=\"σ(x)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS)\n",
        "    ax_sig.scatter(X[:, 0], X[:, 1], c=\"red\", s=60, edgecolors=\"k\")\n",
        "    style_axis(ax_sig, xlabel=\"x_1\", ylabel=\"x_2\", title=f\"{name} — std\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "    ax_sig.set_aspect(\"equal\")\n",
        "axes[0, 0].set_xlabel(\"x_1\", fontsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "axes[1, 0].set_xlabel(\"x_1\", fontsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "axes[2, 0].set_xlabel(\"x_1\", fontsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "axes[2, 1].set_xlabel(\"x_1\", fontsize=DEFAULT_FONT_SIZE_AXIS)\n",
        "plt.tight_layout()\n",
        "if IF_EXPORT_PLOT:\n",
        "    out_dir = PLOT_EXPORT_DIR\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path = out_dir / f\"function_1_gp_three_kernels.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig.savefig(out_path, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path)\n",
        "if IF_SHOW_PLOT:\n",
        "    plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6972a318",
      "metadata": {},
      "source": [
        "### 3.2 The Acquisition Functions $\\alpha$(x)\n",
        "\n",
        "* Expected Improvement (EI)\n",
        "\n",
        "* Upper Confidence Bound (UCB)\n",
        "\n",
        "* Probability of Improvement (PI)\n",
        "\n",
        "* Thompson Sampling\n",
        "\n",
        "* Entropy Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc8878e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.831414Z",
          "iopub.status.busy": "2026-01-31T21:19:32.831291Z",
          "iopub.status.idle": "2026-01-31T21:19:32.841882Z",
          "shell.execute_reply": "2026-01-31T21:19:32.841003Z"
        }
      },
      "outputs": [],
      "source": [
        "# ACQUISITION FUNCTION(s) — coefficients from \"Coefficients of the Probabilistic Surrogate Models\" cell (XI_EI_PI, KAPPA_UCB)\n",
        "\n",
        "# --- EXPECTED IMPROVEMENT: EI = E[max(f(x) − f(x⁺), 0)] ---\n",
        "# Acquisition maximised over candidate_pts (uniform coverage: CANDIDATE_SAMPLING_METHOD, e.g. 'grid')\n",
        "y_best_EI = y.max()  # best observed value so far (EI baseline)\n",
        "EI_RBF = expected_improvement(mu_cand_RBF, sigma_cand_RBF, y_best_EI, xi=XI_EI_PI)\n",
        "x_best_EI_RBF = candidate_pts[np.argmax(EI_RBF)]\n",
        "EI_Matern = expected_improvement(mu_cand_Matern, sigma_cand_Matern, y_best_EI, xi=XI_EI_PI)\n",
        "x_best_EI_Matern = candidate_pts[np.argmax(EI_Matern)]\n",
        "\n",
        "\n",
        "# --- UPPER CONFIDENCE BOUND: UCB = μ(x) + κσ(x) ---\n",
        "UCB_RBF = upper_confidence_bound(mu_cand_RBF, sigma_cand_RBF, kappa=KAPPA_UCB)\n",
        "x_best_UCB_RBF = candidate_pts[np.argmax(UCB_RBF)]\n",
        "UCB_Matern = upper_confidence_bound(mu_cand_Matern, sigma_cand_Matern, kappa=KAPPA_UCB)\n",
        "x_best_UCB_Matern = candidate_pts[np.argmax(UCB_Matern)]\n",
        "\n",
        "\n",
        "# --- PROBABILITY OF IMPROVEMENT: PI = P(f(x) > f(x⁺)) ---\n",
        "PI_RBF = probability_of_improvement(mu_cand_RBF, sigma_cand_RBF, y_best_EI, xi=XI_EI_PI)\n",
        "x_best_PI_RBF = candidate_pts[np.argmax(PI_RBF)]\n",
        "PI_Matern = probability_of_improvement(mu_cand_Matern, sigma_cand_Matern, y_best_EI, xi=XI_EI_PI)\n",
        "x_best_PI_Matern = candidate_pts[np.argmax(PI_Matern)]\n",
        "\n",
        "\n",
        "# --- THOMPSON SAMPLING: sample from posterior, then maximize the sample ---\n",
        "sample_thompson_RBF = thompson_sampling_sample(mu_cand_RBF, sigma_cand_RBF)\n",
        "x_thomson_RBF = candidate_pts[np.argmax(sample_thompson_RBF)]\n",
        "sample_thompson_Matern = thompson_sampling_sample(mu_cand_Matern, sigma_cand_Matern)\n",
        "x_thomson_Matern = candidate_pts[np.argmax(sample_thompson_Matern)]\n",
        "\n",
        "\n",
        "# --- ENTROPY SEARCH: proxy −σ(x) (favor reducing uncertainty) ---\n",
        "ES_RBF = entropy_search(mu_cand_RBF, sigma_cand_RBF, y_best_EI, xi=XI_EI_PI)\n",
        "x_entropy_RBF = candidate_pts[np.argmax(ES_RBF)]\n",
        "ES_Matern = entropy_search(mu_cand_Matern, sigma_cand_Matern, y_best_EI, xi=XI_EI_PI)\n",
        "x_entropy_Matern = candidate_pts[np.argmax(ES_Matern)]\n",
        "\n",
        "\n",
        "print(f'Next point (EI) with RBF kernel and xi = {XI_EI_PI}: x_best_EI = ({x_best_EI_RBF[0]:.2f}, {x_best_EI_RBF[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (EI) with Matérn kernel and xi = {XI_EI_PI}: x_best_EI = ({x_best_EI_Matern[0]:.2f}, {x_best_EI_Matern[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (UCB) with RBF kernel and κ = {KAPPA_UCB}: x_best_UCB = ({x_best_UCB_RBF[0]:.2f}, {x_best_UCB_RBF[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (UCB) with Matérn kernel and κ = {KAPPA_UCB}: x_best_UCB = ({x_best_UCB_Matern[0]:.2f}, {x_best_UCB_Matern[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (PI) with RBF kernel and xi = {XI_EI_PI}: x_best_PI = ({x_best_PI_RBF[0]:.2f}, {x_best_PI_RBF[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (PI) with Matérn kernel and xi = {XI_EI_PI}: x_best_PI = ({x_best_PI_Matern[0]:.2f}, {x_best_PI_Matern[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (Thompson) with RBF kernel: x_thomson = ({x_thomson_RBF[0]:.2f}, {x_thomson_RBF[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (Thompson) with Matérn kernel: x_thomson = ({x_thomson_Matern[0]:.2f}, {x_thomson_Matern[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (Entropy) with RBF kernel: x_entropy = ({x_entropy_RBF[0]:.2f}, {x_entropy_RBF[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "print(f'Next point (Entropy) with Matérn kernel: x_entropy = ({x_entropy_Matern[0]:.2f}, {x_entropy_Matern[1]:.2f}) | current best observed y = {y_best_EI:.2f}')\n",
        "\n",
        "# Kernel selection sensitivity: Delta = (RBF suggestion) - (Matern suggestion)\n",
        "delta_EI = x_best_EI_RBF - x_best_EI_Matern\n",
        "delta_UCB = x_best_UCB_RBF - x_best_UCB_Matern\n",
        "delta_PI = x_best_PI_RBF - x_best_PI_Matern\n",
        "delta_Thompson = x_thomson_RBF - x_thomson_Matern\n",
        "delta_Entropy = x_entropy_RBF - x_entropy_Matern\n",
        "print('\\nKernel selection sensitivity (Delta = RBF - Matern):')\n",
        "print(f'  EI:       Delta: x_1 = {delta_EI[0]:.2f}, x_2 = {delta_EI[1]:.2f}')\n",
        "print(f'  UCB:      Delta: x_1 = {delta_UCB[0]:.2f}, x_2 = {delta_UCB[1]:.2f}')\n",
        "print(f'  PI:       Delta: x_1 = {delta_PI[0]:.2f}, x_2 = {delta_PI[1]:.2f}')\n",
        "print(f'  Thompson: Delta: x_1 = {delta_Thompson[0]:.2f}, x_2 = {delta_Thompson[1]:.2f}')\n",
        "print(f'  Entropy:  Delta: x_1 = {delta_Entropy[0]:.2f}, x_2 = {delta_Entropy[1]:.2f}')\n",
        "print(50*'-')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e3ef8b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.843614Z",
          "iopub.status.busy": "2026-01-31T21:19:32.843463Z",
          "iopub.status.idle": "2026-01-31T21:19:32.847555Z",
          "shell.execute_reply": "2026-01-31T21:19:32.846981Z"
        }
      },
      "outputs": [],
      "source": [
        "# Sanity checks: (0,0) suggestions and low sigma (degenerate EI/PI)\n",
        "def _is_near_zero(x, tol=1e-6):\n",
        "    x = np.asarray(x).ravel()\n",
        "    return x.size >= 2 and np.all(np.abs(x) < tol)\n",
        "\n",
        "sigma_RBF_max = np.nanmax(sigma_gp_RBF) if sigma_gp_RBF.size else 0.0\n",
        "sigma_Matern_max = np.nanmax(sigma_gp_Matern) if sigma_gp_Matern.size else 0.0\n",
        "SIGMA_WARN = 1e-6\n",
        "if sigma_RBF_max < SIGMA_WARN or sigma_Matern_max < SIGMA_WARN:\n",
        "    print(f\"⚠ GP uncertainty very low: sigma_RBF_max = {sigma_RBF_max:.2e}, sigma_Matern_max = {sigma_Matern_max:.2e}. EI/PI can be degenerate (suggest 0,0).\")\n",
        "\n",
        "suggestions = [\n",
        "    (x_best_EI_RBF, 'EI RBF'), (x_best_EI_Matern, 'EI Matern'),\n",
        "    (x_best_UCB_RBF, 'UCB RBF'), (x_best_UCB_Matern, 'UCB Matern'),\n",
        "    (x_best_PI_RBF, 'PI RBF'), (x_best_PI_Matern, 'PI Matern'),\n",
        "    (x_thomson_RBF, 'Thompson RBF'), (x_thomson_Matern, 'Thompson Matern'),\n",
        "    (x_entropy_RBF, 'Entropy RBF'), (x_entropy_Matern, 'Entropy Matern'),\n",
        "]\n",
        "near_zero = [name for x, name in suggestions if _is_near_zero(x)]\n",
        "if near_zero:\n",
        "    print(f\"Suggestions at or near (0,0): {', '.join(near_zero)}. Consider using baseline (exploit/explore) or Thompson.\")\n",
        "else:\n",
        "    print(\"No acquisition suggestion at (0,0); checks OK.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa1b3ae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.849028Z",
          "iopub.status.busy": "2026-01-31T21:19:32.848918Z",
          "iopub.status.idle": "2026-01-31T21:19:32.853019Z",
          "shell.execute_reply": "2026-01-31T21:19:32.852572Z"
        }
      },
      "outputs": [],
      "source": [
        "# Baseline: suggest next x without GP (compare later with acquisition-function suggestions).\n",
        "# Why exploit? Function 1 has one sparse hotspot — best observed y is near that peak, so a small\n",
        "# random step from best_x refines the search locally. Explore (random in [0,1]²) would waste\n",
        "# queries in empty regions. Bounds low/high + margin are for optional use; we clip to [0,1] anyway.\n",
        "rng = np.random.default_rng(42)\n",
        "best_idx = np.argmax(y)\n",
        "best_x = X[best_idx].copy()\n",
        "\n",
        "# Infer bounds from data (or use [0,1]^2 from config)\n",
        "low = X.min(axis=0)\n",
        "high = X.max(axis=0)\n",
        "# Widen slightly so we can suggest points near the edges\n",
        "margin = 0.05\n",
        "low = np.clip(low - margin, 0, 1)\n",
        "high = np.clip(high + margin, 0, 1)\n",
        "\n",
        "# Option A: small step from best (exploit)\n",
        "step = 0.1\n",
        "next_x_exploit = best_x + rng.uniform(-step, step, size=2)\n",
        "next_x_exploit = np.clip(next_x_exploit, 0, 1)\n",
        "\n",
        "# Option B: random in domain (explore)\n",
        "next_x_explore = rng.uniform(0, 1, size=2)\n",
        "\n",
        "# Option C: point with highest distance to nearest observation (on candidate_pts, same uniform coverage)\n",
        "min_dist_cand = np.min(np.sqrt(((candidate_pts[:, None, :] - X[None, :, :]) ** 2).sum(axis=2)), axis=1)\n",
        "idx_high_dist = np.argmax(min_dist_cand)\n",
        "next_x_high_dist = np.asarray(candidate_pts[idx_high_dist]).ravel()\n",
        "next_x_high_dist = np.clip(next_x_high_dist, 0.0, 0.999999)\n",
        "\n",
        "# Choose one to submit (exploit / explore / high-distance)\n",
        "next_x = next_x_exploit\n",
        "print(\"Suggested next x (exploit):\", next_x)\n",
        "print(\"Alternative (explore):\", next_x_explore)\n",
        "print(\"Alternative (high distance to obs):\", next_x_high_dist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130d0d5d",
      "metadata": {},
      "source": [
        "### Do the acquisition functions suggest similar points?\n",
        "Pairwise distances below: small values mean two strategies agree; large values mean they point to different regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b54ba92",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare suggested points (RBF acquisition + high-distance baseline)\n",
        "names = ['EI', 'UCB', 'PI', 'Thompson', 'Entropy', 'High dist']\n",
        "pts = [np.asarray(x).ravel() for x in [x_best_EI_RBF, x_best_UCB_RBF, x_best_PI_RBF, x_thomson_RBF, x_entropy_RBF, next_x_high_dist]]\n",
        "n_pts = len(pts)\n",
        "dists = np.zeros((n_pts, n_pts))\n",
        "for i in range(n_pts):\n",
        "    for j in range(n_pts):\n",
        "        dists[i, j] = np.linalg.norm(pts[i] - pts[j])\n",
        "print(\"Pairwise L2 distances between acquisition suggestions:\")\n",
        "for i in range(n_pts):\n",
        "    for j in range(i + 1, n_pts):\n",
        "        print(f\"  {names[i]} vs {names[j]}: {dists[i, j]:.4f}\")\n",
        "max_d = dists.max()\n",
        "if max_d < 0.15:\n",
        "    print(\"\\n>>> Suggestions are similar (max pairwise distance < 0.15).\")\n",
        "else:\n",
        "    print(f\"\\n>>> Suggestions differ (max pairwise distance = {max_d:.4f}); consider comparing strategies.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "880681e8",
      "metadata": {},
      "source": [
        "## 4. Illustrate the locations on the proposed query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f0ce36",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:32.854686Z",
          "iopub.status.busy": "2026-01-31T21:19:32.854553Z",
          "iopub.status.idle": "2026-01-31T21:19:33.009139Z",
          "shell.execute_reply": "2026-01-31T21:19:33.008500Z"
        }
      },
      "outputs": [],
      "source": [
        "# PLOT ALL ACQUISITION FUNCTIONS + BASELINE (exploit / explore / high distance from cell above)\n",
        "# Acquisition and high-distance points are from uniform-coverage candidates (CANDIDATE_SAMPLING_METHOD)\n",
        "\n",
        "_method = CANDIDATE_SAMPLING_METHOD\n",
        "X_best_combined = np.array([x_best_EI_RBF, x_best_UCB_RBF, x_best_PI_RBF, x_thomson_RBF, x_entropy_RBF])\n",
        "labels_combined = [f'EI RBF ({_method})', f'UCB RBF ({_method})', f'PI RBF ({_method})', f'Thompson RBF ({_method})', f'Entropy RBF ({_method})']\n",
        "colors_combined = plt.cm.cool(np.linspace(0, 1, len(X_best_combined)))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 7))\n",
        "cf = ax.contourf(X1g, X2g, Y_grid, levels=22, cmap=\"turbo\", alpha=0.8)\n",
        "add_colorbar(cf, ax=ax, label=\"y (interpolated)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS)\n",
        "ax.scatter(X[:, 0], X[:, 1], c=y, s=80, cmap=\"inferno\", edgecolors=\"k\", linewidths=1.5, zorder=5, label=\"Observations\")\n",
        "for i, (pt, lbl) in enumerate(zip(X_best_combined, labels_combined)):\n",
        "    ax.scatter(pt[0], pt[1], c=[colors_combined[i]], s=80, marker='s', edgecolors=\"k\", linewidths=1.5, zorder=10, alpha=0.95, label=lbl)\n",
        "    ax.annotate(lbl, (pt[0], pt[1]), xytext=(5, 5), textcoords=\"offset points\", fontsize=DEFAULT_FONT_SIZE_AXIS, alpha=0.9, zorder=11)\n",
        "# Baseline suggestions (from cell above: exploit, explore, high distance to obs)\n",
        "ax.scatter(next_x[0], next_x[1], c='k', s=80, marker='^', edgecolors='w', linewidths=1.5, zorder=10, alpha=0.95, label='Naive exploit')\n",
        "ax.annotate('Naive exploit', (next_x[0], next_x[1]), xytext=(5, 5), textcoords=\"offset points\", fontsize=DEFAULT_FONT_SIZE_AXIS, alpha=0.9, zorder=11)\n",
        "ax.scatter(next_x_explore[0], next_x_explore[1], c='dimgray', s=80, marker='v', edgecolors='w', linewidths=1.5, zorder=10, alpha=0.95, label='Random explore')\n",
        "ax.annotate('Random explore', (next_x_explore[0], next_x_explore[1]), xytext=(5, 5), textcoords=\"offset points\", fontsize=DEFAULT_FONT_SIZE_AXIS, alpha=0.9, zorder=11)\n",
        "# New method: uniform-coverage suggestion — point farthest from observations on candidate set\n",
        "ax.scatter(next_x_high_dist[0], next_x_high_dist[1], c='blue', s=80, marker='v', edgecolors='k', linewidths=1.5, zorder=10, alpha=0.95, label=f'Highest distance (uniform-coverage/{_method})')\n",
        "ax.annotate(f'Uniform-coverage ({_method})', (next_x_high_dist[0], next_x_high_dist[1]), xytext=(5, 5), textcoords=\"offset points\", fontsize=DEFAULT_FONT_SIZE_AXIS, alpha=0.9, zorder=11)\n",
        "style_axis(ax, xlabel=\"x_1\", ylabel=\"x_2\", title=f\"All acquisition next points + baseline (acquisition over {_method} candidates)\", font_size_axis=DEFAULT_FONT_SIZE_AXIS, font_size_titles=DEFAULT_FONT_SIZE_TITLES)\n",
        "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.12), fontsize=DEFAULT_FONT_SIZE_AXIS, ncol=4, frameon=True)\n",
        "ax.set_aspect(\"equal\")\n",
        "plt.tight_layout()\n",
        "fig.subplots_adjust(bottom=0.22)\n",
        "if IF_SHOW_PLOT:\n",
        "    plt.show()\n",
        "if IF_EXPORT_PLOT:\n",
        "    out_dir = PLOT_EXPORT_DIR\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path = out_dir / f\"function_1_all_acquisition_points.{DEFAULT_EXPORT_FORMAT}\"\n",
        "    fig.savefig(out_path, dpi=DEFAULT_EXPORT_DPI, format=DEFAULT_EXPORT_FORMAT)\n",
        "    print(\"Plot saved to\", out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be73bba9",
      "metadata": {},
      "source": [
        "## 5. Select next query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25784bfd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:33.010820Z",
          "iopub.status.busy": "2026-01-31T21:19:33.010680Z",
          "iopub.status.idle": "2026-01-31T21:19:33.013407Z",
          "shell.execute_reply": "2026-01-31T21:19:33.012908Z"
        }
      },
      "outputs": [],
      "source": [
        "# In this cell we select the next query to submit.\n",
        "# F1: sparse hotspot — use high-distance (farthest from observations) to explore until we get a non-zero reading.\n",
        "# Alternatives: x_best_UCB_RBF (explore with UCB), x_best_EI_RBF, x_thomson_RBF, next_x_exploit (once hotspot found).\n",
        "next_x = next_x_high_dist  # farthest from observations (explore); switch to EI/UCB/exploit after improvement\n",
        "next_x = np.clip(np.asarray(next_x).ravel(), 0.0, 0.999999)\n",
        "print(f\"Next query (high distance to obs): ({next_x[0]:.4f}, {next_x[1]:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b1aba9",
      "metadata": {},
      "source": [
        "## 6. Append new feedback (after portal returns)\n",
        "\n",
        "After you submit and receive the new **(x, y)** from the portal for Function 1, paste the values below and run this cell. It appends the new point to a local dataset under `data/problems/function_1/`. The next time you run the notebook from the top, section 1 will load from this local dataset (initial + all appended points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd69c24b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:33.014902Z",
          "iopub.status.busy": "2026-01-31T21:19:33.014781Z",
          "iopub.status.idle": "2026-01-31T21:19:33.018692Z",
          "shell.execute_reply": "2026-01-31T21:19:33.018106Z"
        }
      },
      "outputs": [],
      "source": [
        "if not IF_APPEND_DATA:\n",
        "    print(\"IF_APPEND_DATA is False; append skipped. Set IF_APPEND_DATA = True and paste portal feedback below to run.\")\n",
        "else:\n",
        "    # Paths (use repo_root from setup cell)\n",
        "    _local_dir = repo_root / \"data\" / \"problems\" / \"function_1\"\n",
        "    assert_not_under_initial_data(_local_dir, project_root=repo_root)\n",
        "    _csv_path = _local_dir / \"observations.csv\"\n",
        "\n",
        "    # Set these from the portal feedback for Function 1 (one new input and one new output)\n",
        "    x_new = np.array([0.472352, 0.625531], dtype=np.float64)  # replace with your submitted input\n",
        "    y_new = -1.802e-144  # replace with the output returned (scalar)\n",
        "\n",
        "    # Load current data (CSV if exists, else initial_data). Under data/ we use only CSV.\n",
        "    if _csv_path.exists():\n",
        "        X_cur, y_cur = load_problem_data_csv(_csv_path)\n",
        "    else:\n",
        "        X_cur, y_cur = load_function_data(function_id=1)\n",
        "\n",
        "    # Append: one new row for inputs, one new value for outputs\n",
        "    x_new = np.atleast_2d(x_new)\n",
        "    X_updated = np.vstack((X_cur, x_new))\n",
        "    y_updated = np.append(y_cur, y_new)\n",
        "\n",
        "    # Save to local directory (do not overwrite read-only initial_data)\n",
        "    _local_dir.mkdir(parents=True, exist_ok=True)\n",
        "    save_problem_data_csv(_local_dir / \"observations.csv\", X_updated, y_updated)\n",
        "    print(\"Appended. Total points:\", len(y_updated))\n",
        "    print(\"Saved to\", _local_dir, \"-> observations.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f659ca",
      "metadata": {},
      "source": [
        "## 7. Save suggestion for submission\n",
        "\n",
        "Write the chosen x to `data/submissions/` so you can upload it to the portal. **Portal format:** `x1-x2-...-xn` with **exactly six decimal places**, values in [0, 0.999999], **hyphens only, no spaces** (e.g. `0.498317-0.625531`). After you receive the new y, run section 6 (Append new feedback) to add it to your dataset, then re-run the notebook for the next round."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffebf17",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-31T21:19:33.020280Z",
          "iopub.status.busy": "2026-01-31T21:19:33.020172Z",
          "iopub.status.idle": "2026-01-31T21:19:33.025671Z",
          "shell.execute_reply": "2026-01-31T21:19:33.025153Z"
        }
      },
      "outputs": [],
      "source": [
        "if IF_EXPORT_QUERIES:\n",
        "    # Portal format: each value 0.XXXXXX (exactly 6 decimals), in [0, 0.999999], hyphen-separated, no spaces\n",
        "    next_x_clip = np.clip(np.asarray(next_x, dtype=np.float64).ravel(), 0.0, 0.999999)\n",
        "    portal_str = \"-\".join(f\"{v:.6f}\" for v in next_x_clip)\n",
        "    out_dir = repo_root / \"data\" / \"submissions\" / \"function_1\"\n",
        "    assert_not_under_initial_data(out_dir, project_root=repo_root)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(out_dir / \"next_input.npy\", next_x_clip)\n",
        "    (out_dir / \"next_input_portal.txt\").write_text(portal_str)\n",
        "    print(\"Saved to\", out_dir / \"next_input.npy\")\n",
        "    print(\"Portal string (copy-paste to portal):\", portal_str)\n",
        "    print(\"Also saved to\", out_dir / \"next_input_portal.txt\")\n",
        "else:\n",
        "    print(\"IF_EXPORT_QUERIES is False; next_input.npy not saved.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
